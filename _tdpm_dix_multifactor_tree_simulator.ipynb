{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### tree algorithm factor trading platform\n",
    "\n",
    "### 팩터별로 바스켓 구성 ==> ls\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xlwings as xw\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n",
    "import datetime as dt\n",
    "import tdpm_kgh.pckg_tools.utils as ut\n",
    "import tdpm_kgh.pckg_stats.statistics as stat\n",
    "from _config_python_pc import *\n",
    "import tqdm\n",
    "import itertools\n",
    "import ray\n",
    "import os\n",
    "from sklearn.preprocessing import StandardScaler\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "### read pickle data and adjust for simulation\n",
    "\n",
    "date_info = pd.read_pickle(FileName.date_info) # read date information\n",
    "date_m = ut.calculate_date(date_info, 'M') # monthly date\n",
    "date_q = ut.calculate_date(date_info,'Q') # quarterly date\n",
    "date_w = ut.calculate_date(date_info, 'W') # weekly date \n",
    "bm_const = pd.read_pickle(FileName.bcmk_const) # read bcmk constituent information\n",
    "price = pd.read_pickle(FileName.stck_price) # read stock price\n",
    "price_d = pd.read_pickle(FileName.stck_price_d) # read stock price dividend adjusted\n",
    "ret_d = stat.calculate_return(price,'D') # timeseries daily return\n",
    "ret_d_stack = ret_d.stack().reset_index() # stacked daily return\n",
    "ret_d_stack.columns = ['date', 'code', 'return'] # stacked daily return column adjusted\n",
    "ret_m = stat.calculate_return(price,'M') # timeseries monthly return \n",
    "ret_m_stack = ret_m.stack().reset_index() # stacked monthly return \n",
    "ret_m_stack.columns = ['date', 'code', 'return'] # stacked monthly return column adjusted \n",
    "list_date = [date_m[x] for x in range(71,len(date_m))] # range of regression date "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PortfolioSimulator:\n",
    "    def __init__(self, return_df, tickers, initial_weights=None, initial_value =1.0):\n",
    "\n",
    "        # self.return_df = return_df[tickers]\n",
    "        self.return_df = return_df[tickers].fillna(0)\n",
    "        self.tickers = tickers\n",
    "        if initial_weights is None:\n",
    "            self.initial_weights = [1/len(tickers) for _ in tickers]\n",
    "        else:\n",
    "            self.initial_weights = initial_weights\n",
    "        self.current_weights = self.initial_weights.copy()\n",
    "        self.initial_value = [initial_value]\n",
    "        \n",
    "\n",
    "    def simulate(self):\n",
    "        cumulative_returns = self.initial_value  # 첫 번째 날의 누적 수익률은 1.0 (100%)\n",
    "        return_series = []\n",
    "        for i in range(len(self.return_df)):\n",
    "            daily_returns = self.return_df.iloc[i]\n",
    "            # valid_returns = daily_returns.dropna()\n",
    "            valid_returns = daily_returns.copy()\n",
    "            valid_weights = [self.current_weights[self.tickers.index(ticker)] for ticker in valid_returns.index]\n",
    "            total_valid_weight = sum(valid_weights)\n",
    "            normalized_weights = [w/total_valid_weight for w in valid_weights]\n",
    "\n",
    "            daily_portfolio_return = sum(weight * ret for weight, ret in zip(normalized_weights, valid_returns))\n",
    "            \n",
    "            # 이전 누적 수익률에 일별 수익률을 반영하여 새로운 누적 수익률 계산\n",
    "            new_cumulative_return = cumulative_returns[-1] * (1 + daily_portfolio_return)\n",
    "            cumulative_returns.append(new_cumulative_return)\n",
    "            return_series.append(daily_portfolio_return)\n",
    "            \n",
    "            new_values = [(weight * (1 + ret)) for weight, ret in zip(normalized_weights, valid_returns)]\n",
    "            total_value = sum(new_values)\n",
    "            self.current_weights = [val / total_value for val in new_values]\n",
    "\n",
    "        self.cumulative_return_series = pd.Series(cumulative_returns[1:], index=self.return_df.index)\n",
    "        self.return_series = pd.Series(return_series, index=self.return_df.index)\n",
    "        \n",
    "        # return self.cumulative_return_series, self.initial_weights, self.current_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "## tqdm_제외 코드 \n",
    "\n",
    "def tree_simulation(strategy: str, data : pd.DataFrame ,ret_df: pd.DataFrame, date_start: str, date_end: str, df_node: pd.DataFrame, directory: str):    \n",
    "    ret_d_adj_flt = ret_df[(ret_df.index>date_start) & (ret_df.index<=date_end)].copy()    \n",
    "    list_simulation = []\n",
    "    for n in range(len(df_node)):\n",
    "        data_flt = list(data[(data['strategy'] == strategy) & (data['tree_node'] == df_node['node'][n])].code)\n",
    "        sim = PortfolioSimulator(ret_d_adj_flt, data_flt, None, 1)\n",
    "        sim.simulate()\n",
    "        list_simulation.append(sim.return_series.to_frame(f'{strategy}_{df_node[\"node\"][n]}'))\n",
    "    \n",
    "    result = pd.concat(list_simulation, axis = 1)\n",
    "    result.to_pickle(f'{directory}{date_start}_{strategy}.pkl')\n",
    "\n",
    "\n",
    "@ray.remote\n",
    "def ray_tree_simulation(strategy: str, data : pd.DataFrame ,ret_df: pd.DataFrame, date_start: str, date_end: str, df_node: pd.DataFrame, directory: str):    \n",
    "    ret_d_adj_flt = ret_df[(ret_df.index>date_start) & (ret_df.index<=date_end)].copy()    \n",
    "    list_simulation = []\n",
    "    for n in range(len(df_node)):\n",
    "        data_flt = list(data[(data['strategy'] == strategy) & (data['tree_node'] == df_node['node'][n])].code)\n",
    "        sim = PortfolioSimulator(ret_d_adj_flt, data_flt, None, 1)\n",
    "        sim.simulate()\n",
    "        list_simulation.append(sim.return_series.to_frame(f'{strategy}_{df_node[\"node\"][n]}'))\n",
    "    \n",
    "    result = pd.concat(list_simulation, axis = 1)\n",
    "    result.to_pickle(f'{directory}{date_start}_{strategy}.pkl')\n",
    "\n",
    "\n",
    "def wrapper_ray_tree_simulation(list_strategy: list, data : pd.DataFrame ,ret_df: pd.DataFrame, date_start: str, date_end: str, df_node: pd.DataFrame, directory: str):\n",
    "    numb_cpu = os.cpu_count()-3\n",
    "    numb_cpu_max = min(len(list_strategy),numb_cpu)\n",
    "    ray.init(num_cpus=numb_cpu_max)\n",
    "    for i in range(0,len(list_strategy),numb_cpu_max): # tqdm.tqdm(range(0,len(name_list),numb_cpu_max))\n",
    "        print(list_strategy[i] +'_process_begins')\n",
    "        strategies = list_strategy[i:i+numb_cpu_max]\n",
    "        actors = []\n",
    "        for strategy in strategies:\n",
    "            actors.append(ray_tree_simulation.remote(strategy, data, ret_df, date_start, date_end, df_node, directory))\n",
    "        ray.get(actors)\n",
    "        print(list_strategy[i] +'_process_ends')\n",
    "    ray.shutdown()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TestPerfomanceV2:\n",
    "    def __init__(self, data:pd.DataFrame):\n",
    "        \"\"\"\n",
    "        data : dataframe (not a string)\n",
    "            index = date\n",
    "            column = strategy\n",
    "            value = normal return \n",
    "        \"\"\"\n",
    "        self.data = np.log(data+1) #convert normal return to log return\n",
    "        \n",
    "        if isinstance(self.data.index[0],str):\n",
    "            try:\n",
    "                self.data.index = pd.to_datetime(self.data.index)\n",
    "            except:\n",
    "                pass\n",
    "        else:\n",
    "            pass\n",
    "\n",
    "        self.list_columns = list(data.columns)\n",
    "        self.len_date = (self.data.index[-1] - self.data.index[0]).days\n",
    "        self.ret_cum = pd.DataFrame()\n",
    "        self.ret_cagr = pd.DataFrame()\n",
    "        self.ret_mean = pd.DataFrame()\n",
    "        self.ret_std = pd.DataFrame()\n",
    "        self.ir = pd.DataFrame()\n",
    "        self.mdd = pd.DataFrame()\n",
    "        self.dd = pd.DataFrame()\n",
    "        self.pdd = pd.DataFrame()\n",
    "        self.dd_avg = pd.DataFrame()\n",
    "        self.score_raw = pd.DataFrame()\n",
    "        self.score_stdz = pd.DataFrame()\n",
    "        self.score = pd.DataFrame()\n",
    "        self.obj = pd.DataFrame()\n",
    "\n",
    "    def get_ret_cum(self):\n",
    "        ret_cum = self.data.sum().to_frame()\n",
    "        ret_cum.columns = ['ret_cum']\n",
    "        ret_cum['ret_cum'] = ret_cum['ret_cum'].apply(lambda x: np.exp(x) - 1)\n",
    "        # ret_cum = ret_cum.to_frame()\n",
    "        self.ret_cum = ret_cum\n",
    "        \n",
    "    def get_ret_cagr(self):\n",
    "        ret_cum = self.data.sum().to_frame()\n",
    "        ret_cum.columns = ['ret_cagr']\n",
    "        ret_cum['ret_cagr'] = ret_cum['ret_cagr'].apply(lambda x: np.exp(x)**(365/self.len_date) - 1)\n",
    "        self.ret_cagr = ret_cum\n",
    "\n",
    "    def get_ret_mean(self, d:int):\n",
    "        if d is None:\n",
    "            d=250\n",
    "        ret_mean = (self.data.mean()*d).to_frame()\n",
    "        ret_mean.columns = ['ret_mean']\n",
    "        self.ret_mean = ret_mean\n",
    "\n",
    "    def get_ret_std(self, d:int):\n",
    "        if d is None:\n",
    "            d=250\n",
    "        ret_std = (self.data.std()*np.sqrt(d)).to_frame()\n",
    "        ret_std.columns = ['ret_std']\n",
    "        self.ret_std = ret_std\n",
    "\n",
    "    def get_drawdown(self, period: int):\n",
    "        '''\n",
    "        period : last period\n",
    "        '''\n",
    "        cum_sum = self.data.cumsum()\n",
    "        cum_max = cum_sum.cummax()\n",
    "        cum_dd = cum_sum-cum_max\n",
    "        self.dd = cum_dd\n",
    "        mdd = cum_dd.min().to_frame()\n",
    "        mdd.columns = ['mdd']\n",
    "        mdd['mdd'] = mdd['mdd'].apply(lambda x: np.exp(x) - 1)\n",
    "        self.mdd = mdd\n",
    "\n",
    "        cum_sum_period = self.data.iloc[-period:,:].cumsum()\n",
    "        cum_max_period = cum_sum_period.iloc[-period:,:].cummax()\n",
    "        cum_dd_period = cum_sum_period-cum_max_period\n",
    "        period_dd = cum_dd_period.iloc[-1,:].to_frame()\n",
    "        period_dd.columns = [f'period({period})_dd']\n",
    "        period_dd[f'period({period})_dd'] = period_dd[f'period({period})_dd'].apply(lambda x: np.exp(x) - 1)\n",
    "        self.pdd = period_dd\n",
    "\n",
    "    def get_ir(self):\n",
    "        if self.ret_cagr.empty and self.ret_std.empty:\n",
    "            self.get_ret_cagr()\n",
    "            self.get_ret_std()\n",
    "            ir = (self.ret_cagr['ret_cagr'] / self.ret_std['ret_std']).to_frame()\n",
    "            ir.columns = ['ir']\n",
    "            self.ir = ir\n",
    "\n",
    "\n",
    "            # ir = (self.ret_cagr['ret_cagr'] / self.ret_std['ret_std']).to_frame()\n",
    "            # ir.columns = ['ir']\n",
    "            # self.ir = ir\n",
    "        else:\n",
    "            # self.get_ret_cagr()\n",
    "            # self.get_ret_std()\n",
    "            # ir = (self.ret_cagr['ret_cagr'] / self.ret_std['ret_std']).to_frame()\n",
    "            # ir.columns = ['ir']\n",
    "            # self.ir = ir\n",
    "            ir = (self.ret_cagr['ret_cagr'] / self.ret_std['ret_std']).to_frame()\n",
    "            ir.columns = ['ir']\n",
    "            self.ir = ir\n",
    "\n",
    "    def get_score_base(self, period = 20, d = 250):\n",
    "        self.get_ret_cum()\n",
    "        self.get_ret_cagr()\n",
    "        self.get_ret_mean(d)\n",
    "        self.get_ret_std(d)\n",
    "        self.get_ir()\n",
    "        self.get_drawdown(period)\n",
    "        final = pd.concat([self.ret_cum, \n",
    "                           self.ret_cagr, \n",
    "                           self.ret_mean, \n",
    "                           self.ret_std,\n",
    "                           self.ir,\n",
    "                           self.mdd,\n",
    "                           self.pdd\n",
    "                           ], axis=1\n",
    "                           )\n",
    "        final = final.sort_values(by=['ir'], ascending=[False])\n",
    "        self.score_raw = final\n",
    "        \n",
    "    def get_score_stdz(self, \n",
    "                       period=20, \n",
    "                       d = 250,\n",
    "                       w_ret_cum = 0, \n",
    "                       w_ret_cagr = 0, \n",
    "                       w_ret_mean = 0, \n",
    "                       w_ret_std = 0, \n",
    "                       w_ir = 0.8, \n",
    "                       w_mdd = 0.5,\n",
    "                       w_period_dd = -0.5\n",
    "                       ):\n",
    "        \n",
    "        weights = {'ret_cum': w_ret_cum,\n",
    "           'ret_cagr': w_ret_cagr,\n",
    "           'ret_mean': w_ret_mean,\n",
    "           'ret_std': w_ret_std,\n",
    "           'ir': w_ir,\n",
    "           'mdd':w_mdd,\n",
    "           f'period({period})_dd': w_period_dd,\n",
    "           }\n",
    "\n",
    "        if self.score_raw.empty:\n",
    "            self.get_score_base(period,d=d)\n",
    "            scaler = StandardScaler()\n",
    "            score_stdz = pd.DataFrame(scaler.fit_transform(self.score_raw), columns=self.score_raw.columns, index = self.score_raw.index)\n",
    "        else:\n",
    "            scaler = StandardScaler()\n",
    "            score_stdz = pd.DataFrame(scaler.fit_transform(self.score_raw), columns=self.score_raw.columns, index = self.score_raw.index)\n",
    "        \n",
    "        score_weighted = score_stdz.mul(pd.Series(weights), axis=1)\n",
    "        score = score_weighted.sum(axis=1).to_frame()\n",
    "        score.columns = ['score']\n",
    "        score = score.sort_values(by=['score'], ascending=False)\n",
    "\n",
    "        self.score_stdz = score_stdz\n",
    "        self.score = score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "120\n",
      "27\n"
     ]
    }
   ],
   "source": [
    "### 기초 데이터 세팅 \n",
    "d = 0 \n",
    "data = pd.read_pickle(f'{Directory.pkl_tmp_dix_factor_tree_node_universe}{list_date[d]}_tree_node.pkl')\n",
    "df_strategy = pd.DataFrame(list(data.strategy.unique()),columns=['strategy'])\n",
    "df_node = pd.DataFrame(list(sorted(set(data.tree_node),reverse= True)), columns=['node'])\n",
    "list_strategy = list(data.strategy.unique())\n",
    "print(len(list_strategy))\n",
    "list_node = list(sorted(set(data.tree_node),reverse= True))\n",
    "print(len(list_node))\n",
    "## display\n",
    "wb = xw.Book(FileName.xl_multifactor)\n",
    "sh = wb.sheets['dix_strategy_tree_algo_sim']\n",
    "sh.range('A10').options(index=False, header=True).value = df_strategy\n",
    "sh.range('B10').options(index=False, header=True).value = df_node"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "120\n"
     ]
    }
   ],
   "source": [
    "### selection 축소\n",
    "list_strategy_sel = ['trt_60',\n",
    "                    'price_momentum',\n",
    "                    'value',\n",
    "                    'momentum',\n",
    "                    'debt',\n",
    "                    'dividend',\n",
    "                    ]\n",
    "list_strategy_sel = list(itertools.permutations(list_strategy_sel,3))\n",
    "list_strategy_sel = [','.join(x) for x in list_strategy_sel]\n",
    "print(len(list_strategy_sel))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_strategy_sel_name = ['_' + name +'.pkl' for name in list_strategy_sel]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_data = []\n",
    "for name in list_strategy_sel_name:\n",
    "    list_data.append(pd.read_pickle(f'{Directory.pkl_tmp_simulation_tree_node}{name}'))\n",
    "data = pd.concat(list_data, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = TestPerfomanceV2(data)\n",
    "test.get_score_base(period=6, d= 12)\n",
    "test.score_raw\n",
    "test.score_raw.to_excel('tree_node_performance.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### monthly_simulation\n",
    "start_date = 113\n",
    "\n",
    "for d in range(start_date,len(list_date)-1):\n",
    "    print(list_date[d] + '_process_begins')\n",
    "    data = pd.read_pickle(f'{Directory.pkl_tmp_dix_factor_tree_node_universe}{list_date[d]}_tree_node.pkl')\n",
    "    wrapper_ray_tree_simulation(list_strategy_sel, data, ret_m, list_date[d], list_date[d+1], df_node, Directory.pkl_tmp_simulation_tree_node) ## monthly_return\n",
    "    \n",
    "    for strategy in list_strategy_sel:\n",
    "        if d == 0 :\n",
    "            data = pd.read_pickle(f'{Directory.pkl_tmp_simulation_tree_node}{list_date[d]}_{strategy}.pkl')\n",
    "            data = data.drop_duplicates()\n",
    "            data.to_pickle(f'{Directory.pkl_tmp_simulation_tree_node}_{strategy}.pkl')\n",
    "            os.remove(f'{Directory.pkl_tmp_simulation_tree_node}{list_date[d]}_{strategy}.pkl')\n",
    "        else:\n",
    "            first = pd.read_pickle(f'{Directory.pkl_tmp_simulation_tree_node}_{strategy}.pkl')\n",
    "            second = pd.read_pickle(f'{Directory.pkl_tmp_simulation_tree_node}{list_date[d]}_{strategy}.pkl')\n",
    "            merge = pd.concat([first,second])\n",
    "            merge = merge.drop_duplicates()\n",
    "            merge.to_pickle(f'{Directory.pkl_tmp_simulation_tree_node}_{strategy}.pkl')\n",
    "            os.remove(f'{Directory.pkl_tmp_simulation_tree_node}{list_date[d]}_{strategy}.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ## with tqdm // \n",
    "\n",
    "# def tree_simulation(strategy: str, data : pd.DataFrame ,ret_df: pd.DataFrame, date_start: str, date_end: str, df_node: pd.DataFrame, directory: str):    \n",
    "#     ret_d_adj_flt = ret_df[(ret_df.index>date_start) & (ret_df.index<=date_end)].copy()    \n",
    "#     list_simulation = []\n",
    "#     for n in range(len(df_node)):\n",
    "#         data_flt = list(data[(data['strategy'] == strategy) & (data['tree_node'] == df_node['node'][n])].code)\n",
    "#         sim = PortfolioSimulator(ret_d_adj_flt, data_flt, None, 1)\n",
    "#         sim.simulate()\n",
    "#         list_simulation.append(sim.return_series.to_frame(f'{strategy}_{df_node[\"node\"][n]}'))\n",
    "    \n",
    "#     result = pd.concat(list_simulation, axis = 1)\n",
    "#     result.to_pickle(f'{directory}{date_start}_{strategy}.pkl')\n",
    "\n",
    "\n",
    "# @ray.remote\n",
    "# def ray_tree_simulation(strategy: str, data : pd.DataFrame ,ret_df: pd.DataFrame, date_start: str, date_end: str, df_node: pd.DataFrame, directory: str):    \n",
    "#     ret_d_adj_flt = ret_df[(ret_df.index>date_start) & (ret_df.index<=date_end)].copy()    \n",
    "#     list_simulation = []\n",
    "#     for n in tqdm.tqdm(range(len(df_node))):\n",
    "#         data_flt = list(data[(data['strategy'] == strategy) & (data['tree_node'] == df_node['node'][n])].code)\n",
    "#         sim = PortfolioSimulator(ret_d_adj_flt, data_flt, None, 1)\n",
    "#         sim.simulate()\n",
    "#         list_simulation.append(sim.return_series.to_frame(f'{strategy}_{df_node[\"node\"][n]}'))\n",
    "    \n",
    "#     result = pd.concat(list_simulation, axis = 1)\n",
    "#     result.to_pickle(f'{directory}{date_start}_{strategy}.pkl')\n",
    "\n",
    "\n",
    "# def wrapper_ray_tree_simulation(list_strategy: list, data : pd.DataFrame ,ret_df: pd.DataFrame, date_start: str, date_end: str, df_node: pd.DataFrame, directory: str):\n",
    "#     numb_cpu = os.cpu_count()-3\n",
    "#     numb_cpu_max = min(len(list_strategy),numb_cpu)\n",
    "#     ray.init(num_cpus=numb_cpu_max)\n",
    "#     for i in range(0,len(list_strategy),numb_cpu_max): # tqdm.tqdm(range(0,len(name_list),numb_cpu_max))\n",
    "#         print(list_strategy[i] +'_process_begins')\n",
    "#         strategies = list_strategy[i:i+numb_cpu_max]\n",
    "#         actors = []\n",
    "#         for strategy in strategies:\n",
    "#             actors.append(ray_tree_simulation.remote(strategy, data, ret_df, date_start, date_end, df_node, directory))\n",
    "#         ray.get(actors)\n",
    "#         print(list_strategy[i] +'_process_ends')\n",
    "#     ray.shutdown()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### daily_simulation : 너무 느려서 일단 포기 \n",
    "for d in range(len(list_date)-1):\n",
    "    print(list_date[d] + '_process_begins')\n",
    "    data = pd.read_pickle(f'{Directory.pkl_tmp_dix_factor_tree_node_universe}{list_date[d]}_tree_node.pkl')\n",
    "    wrapper_ray_tree_simulation(list_strategy, data, ret_d, list_date[d], list_date[d+1], df_node, Directory.pkl_tmp_simulation_tree_node) # daily_return\n",
    "    \n",
    "    for strategy in list_strategy:\n",
    "        if d == 0 :\n",
    "            data = pd.read_pickle(f'{Directory.pkl_tmp_simulation_tree_node}{list_date[d]}_{strategy}.pkl')\n",
    "            data.to_pickle(f'{Directory.pkl_tmp_simulation_tree_node}_{strategy}.pkl')\n",
    "        else:\n",
    "            first = pd.read_pickle(f'{Directory.pkl_tmp_simulation_tree_node}_{strategy}.pkl')\n",
    "            second = pd.read_pickle(f'{Directory.pkl_tmp_simulation_tree_node}{list_date[d]}_{strategy}.pkl')\n",
    "            merge = pd.concat([first,second])\n",
    "            merge.to_pickle(f'{Directory.pkl_tmp_simulation_tree_node}_{strategy}.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ret_m_flt = ret_m[(ret_m.index>list_date[0]) & (ret_m.index<=list_date[1])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "strategy = list_strategy[0]\n",
    "n = 2\n",
    "codes = list(data[(data['strategy'] == strategy) & (data['tree_node'] == df_node['node'][n])].code)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sim = PortfolioSimulator(ret_m_flt, codes)\n",
    "sim.simulate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sim.return_series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ret_d_adj = ret_d.fillna(0).copy()\n",
    "list_simulation = []\n",
    "ret_d_adj_flt = ret_d_adj[(ret_d_adj.index>list_date[d]) & (ret_d_adj.index<=list_date[d + 1])]\n",
    "for s in range(len(df_strategy)):\n",
    "    print(s)\n",
    "    for n in tqdm.tqdm(range(len(df_node))):\n",
    "        data_flt = list(data[(data['strategy'] == df_strategy['strategy'][s]) & (data['tree_node'] == df_node['node'][n])].code)\n",
    "        sim = PortfolioSimulator(ret_d_adj_flt, data_flt, None, 1)\n",
    "        sim.simulate()\n",
    "        list_simulation.append(sim.return_series.to_frame(f'{df_strategy[\"strategy\"][s]}_{df_node[\"node\"][n]}'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# ## 너무 느림 \n",
    "# list_data = []\n",
    "# for d in tqdm.tqdm(range(len(list_date))):\n",
    "#     data = pd.read_pickle(f'{Directory.pkl_tmp_dix_factor_tree_node_universe}{list_date[d]}_tree_node.pkl')\n",
    "#     data_flt = data[(data['strategy'] == df_strategy['strategy'][0])]\n",
    "#     list_data.append(data_flt)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def wrapper_simulation(return_df : pd.DataFrame, rebal_date : list, port : pd.DataFrame, cost = 0.002):\n",
    "    \n",
    "    ## pseudo code 작성중 \n",
    "    \n",
    "    \"\"\"\n",
    "    return_df : 수익률 time series, index - date, column - stock code, value - return\n",
    "    rebal_date : list of relancing date\n",
    "    port : dataframe , column date, code, weight\n",
    "                        date       code   weight\n",
    "                        2005-12-29 Axxxx    0.25\n",
    "                        2005-12-29 Axxxx    0.25\n",
    "                        ...\n",
    "                        2006-01-31 Axxxx    0.25\n",
    "    \"\"\"\n",
    "    ## pseudo code \n",
    "    result = []\n",
    "    for i in range(0,len(rebal_date)-1):\n",
    "        \n",
    "        if i == 0 :\n",
    "            initial_value = 1\n",
    "        else :\n",
    "            initial_value = simulation.iloc[-1,:].value\n",
    "\n",
    "        return_df_cut = return_df[return_df.index > rebal_date[i] & return_df.index > rebal_date[i+1]]\n",
    "        code = port[port.date == rebal_date[i]].code.to_list()\n",
    "        weight = port[port.date == rebal_date[i]].weight.to_list()\n",
    "\n",
    "        sim = PortfolioSimulator(return_df_cut, code, weight, initial_value)\n",
    "        sim.simulate()\n",
    "        simulation = sim.cumulative_return_series\n",
    "\n",
    "        ### cost 계산\n",
    "        ### 바로 빼면 안되고 종목별로 매핑해서 빼야함\n",
    "        current_weights = sim.current_weights\n",
    "        rebal_weights = port[port.date == rebal_date[i+1]].weight.to_list()\n",
    "        _cost = (current_weights - rebal_weights) * cost\n",
    "        simulation.iloc[-1,:] = simulation.iloc[-1,:] - _cost\n",
    "        \n",
    "        result = result.append(simulation)\n",
    "    \n",
    "    result = pd.concat(result)\n",
    "    return result"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "algo_trd",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
